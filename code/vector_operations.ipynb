{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename: str):\n",
    "    with open(os.path.join(filename, 'vocab', 'word_to_idx.json'), 'r', encoding='utf-8') as f:\n",
    "        word_to_idx = json.load(f)\n",
    "    with open(os.path.join(filename, 'vocab', 'idx_to_word.json'), 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    idx_to_word = {int(k): v for k, v in data.items()}\n",
    "\n",
    "    embeddings = np.load(os.path.join(filename, 'model', 'word_embeddings.npy'))\n",
    "    return embeddings, {\"w2i\": word_to_idx, \"i2w\": idx_to_word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, vocab = load_embeddings('../experiment/wikitext-2/CBOW/08-07-2023_23-58-38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = (embeddings**2).sum(axis=1, keepdims=True) ** (1 / 2)\n",
    "embeddings_norm = embeddings / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_op(a, b, c, d):\n",
    "    \n",
    "    if a not in vocab[\"w2i\"] or b not in vocab[\"w2i\"] or c not in vocab[\"w2i\"] or d not in vocab[\"w2i\"]:\n",
    "        return False\n",
    "\n",
    "    emb1 = embeddings_norm[vocab[\"w2i\"][a]]\n",
    "    emb2 = embeddings_norm[vocab[\"w2i\"][b]]\n",
    "    emb3 = embeddings_norm[vocab[\"w2i\"][c]]\n",
    "\n",
    "    emb4 = emb2 - emb1 + emb3\n",
    "    emb4_norm = (emb4**2).sum() ** (1 / 2)\n",
    "    emb4 = emb4 / emb4_norm\n",
    "\n",
    "    emb4 = np.reshape(emb4, (len(emb4), 1))\n",
    "    dists = np.matmul(embeddings_norm, emb4).flatten()\n",
    "\n",
    "    top5 = np.argsort(-dists)[:5]\n",
    "\n",
    "    ret = vocab[\"w2i\"][d] in top5\n",
    "\n",
    "    # if ret:\n",
    "    #     print(f\"a - b \")\n",
    "    #     for word_id in top5:\n",
    "    #         print(\"{}: {:.3f}\".format(vocab[\"i2w\"][word_id.item()], dists[word_id]))    \n",
    "\n",
    "    # top5 = np.argsort(-dists)[:10]\n",
    "    # for word_id in top5:\n",
    "    #     print(\"{}: {:.3f}\".format(vocab[\"i2w\"][word_id.item()], dists[word_id]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33277, 300)\n",
      "float32\n",
      "(33277, 300)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "print(embeddings.dtype)\n",
    "\n",
    "print(embeddings_norm.shape)\n",
    "print(embeddings_norm.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/word-test.v1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    word_test = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      ": capital-common-countries\n",
      "0 506\n",
      ": capital-world\n",
      "0 4524\n",
      ": currency\n",
      "0 866\n",
      ": city-in-state\n",
      "0 2467\n",
      ": family\n",
      "35 506\n",
      ": gram1-adjective-to-adverb\n",
      "0 992\n",
      ": gram2-opposite\n",
      "0 812\n",
      ": gram3-comparative\n",
      "14 1332\n",
      ": gram4-superlative\n",
      "6 1122\n",
      ": gram5-present-participle\n",
      "0 1056\n",
      ": gram6-nationality-adjective\n",
      "2 1599\n",
      ": gram7-past-tense\n",
      "73 1560\n",
      ": gram8-plural\n",
      "11 1332\n",
      ": gram9-plural-verbs\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for line in word_test:\n",
    "    line = line.strip()\n",
    "\n",
    "    if len(line) == 0 or line.startswith(\"//\"):\n",
    "        continue\n",
    "    elif line.startswith(\": \"):\n",
    "        print(count, total)\n",
    "        print(line)\n",
    "        count = 0\n",
    "        total = 0\n",
    "    else:\n",
    "        line = line.split()\n",
    "        if vector_op(line[0], line[1], line[2], line[3]):\n",
    "            count += 1\n",
    "        total += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
